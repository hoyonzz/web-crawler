import time
from bs4 import BeautifulSoup
from .base_crawler import BaseCrawler
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from typing import Dict

class WantedCrawler(BaseCrawler):
    # ì›í‹°ë“œ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬

    def __init__(self):
        # ë¶€ëª¨ í´ë˜ìŠ¤ __init__ì„ í˜¸ì¶œí•˜ì—¬ base_url ì „ë‹¬
        super().__init__("https://www.wanted.co.kr/")

    def crawl(self, keyword: str = "ë°±ì—”ë“œ", pages_to_crawl: int = 1, is_newbie: bool = False):
        # BaseCrawlerì˜ ì˜ë¬´ ì¡°í•­ì„ ì‹¤ì œë¡œ êµ¬í˜„, ì›í‹°ë“œ ì±„ìš© ì •ë³´ í¬ë¡¤ë§í•˜ì—¬ list of dict í˜•íƒœë¡œ ë°˜í™˜
        print(f"ì›í‹°ë“œì—ì„œ 'ì‹ ì…' í•„í„°: {is_newbie}, '{keyword}' í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
        # í¬ì§€ì…˜ íƒ­ì˜ URLë¡œ ë°”ë¡œ ì ‘ê·¼í•˜ì—¬ ë¶ˆí•„ìš”í•œ í´ë¦­ ê³¼ì • ìƒëµ
        target_url = f"{self.base_url}/search?query={keyword}&tab=position"
        self.driver.get(target_url)
        self._random_sleep()

        if is_newbie:
            print("   -> 'ì‹ ì…' í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤...")
            try:
                # 'ê²½ë ¥' í•„í„° ë²„íŠ¼ í´ë¦­
                experience_button = self.driver.find_element(By.CSS_SELECTOR, 'button[data-filter-name="experience"]')
                experience_button.click()
                self._random_sleep()

                # ìŠ¬ë¼ì´ë” ì¡°ì‘
                slider_handlers = self.driver.find_elements(By.CLASS_NAME, 'rc-slider-handle')
                if len(slider_handlers) > 1:
                    right_handle = slider_handlers[1]
                    right_handle.send_keys(Keys.ARROW_LEFT * 20)
                    
                    print("   ->ê²½ë ¥ ìŠ¬ë¼ì´ë”ë¥¼ 'ì‹ ì…'ìœ¼ë¡œ ì¡°ì‘í–ˆìŠµë‹ˆë‹¤.")
                    self._random_sleep()

                # 'ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.
                apply_button = self.driver.find_element(By.XPATH, "//button[span[text()='ì ìš©í•˜ê¸°']]")
                apply_button.click()
                print("   -> 'ì ìš©í•˜ê¸°' ë²„íŠ¼ í´ë¦­. í•„í„° ê²°ê³¼ ë¡œë”©ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")
                time.sleep(5)

                print("   ->'ì‹ ì…'í•„í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                print(f"   ğŸš¨ [ì˜¤ë¥˜] 'ì‹ ì…' í•„í„° ì ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


        # ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ë°ì´í„° ìˆ˜ì§‘
        print(" - ë¬´í•œ ìŠ¤í¬ë¡¤ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        last_height = self.driver.execute_script('return document.documentElement.scrollHeight')

        # í‚¤ë³´ë“œ ì…ë ¥ì„ ë°›ì„ ëŒ€ìƒì„ ì§€ì •
        body = self.driver.find_element(By.TAG_NAME, 'body')

        patience = 5
        patience_counter = 0

        while True:
            body.send_keys(Keys.END)


            # self.driver.execute_script('window.scrollTo(0, document.documentElement.scrollHeight);')
            self._random_sleep()
            new_height = self.driver.execute_script('return document.documentElement.scrollHeight')

            if new_height == last_height:
                patience_counter += 1
                print(f" - í˜ì´ì§€ ë†’ì´ ë³€í™” ì—†ìŒ.(ì¸ë‚´ì‹¬: {patience_counter}/{patience})")
                if patience_counter >= patience:
                    print(" - ìŠ¤í¬ë¡¤ì´ í˜ì´ì§€ ëì— ë„ë‹¬í–ˆê±°ë‚˜, ë” ì´ìƒ ë¡œë”©ë˜ì§€ ì•Šì•„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
            else:
                # ë†’ì´ê°€ ë³€í–ˆë‹¤ë©´, ì¸ë‚´ì‹¬ ì¹´ìš´í„° ì´ˆê¸°í™”
                patience_counter = 0

            last_height = new_height

        # ë°ì´í„° ì¶”ì¶œ ë° ê°€ê³µ
        job_data = []
        soup = BeautifulSoup(self.driver.page_source, 'lxml')
        job_cards = soup.select("div[role='listitem'] a")

        for card in job_cards:
            try:
                title = card.select_one("strong[class*='JobCard_title']").text
                company_name = card.select_one("span[class*='CompanyName']").text
                link = "https://www.wanted.co.kr" + card['href']
                job_data.append({"title": title, "company": company_name, "link":link, "source": "Wanted"})
            except Exception:
                continue
        print(f"ì›í‹°ë“œì—ì„œ ì´ {len(job_data)}ê°œì˜ ê³µê³ ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return job_data
    
    def get_job_description(self, url: str) -> Dict[str, str]:
        # ì›í‹°ë“œì˜ ìƒì„¸ í˜ì´ì§€ì˜ ë³¸ë¬¸ ë‚´ìš© ìˆ˜ì§‘:ìƒì„¸í˜ì´ì§€ì— ë°©ë¬¸, 'ë”ë³´ê¸°'ë²„íŠ¼ í´ë¦­, ì „ì²´ ë³¸ë¬¸ ë‚´ìš© ìˆ˜ì§‘
        description = ""
        deadline = "í™•ì¸ í•„ìš”"

        try:
            self.driver.get(url)
            self._random_sleep()

            # 1. í˜ì´ì§€ í¼ì¹˜ëŠ” ë²„íŠ¼ í´ë¦­ ë¡œì§
            try:
                more_button_xpath = "//button[span[text()='ìƒì„¸ ì •ë³´ ë” ë³´ê¸°']]"
                more_button = self.driver.find_element(By.XPATH, more_button_xpath)

                self.driver.execute_script("arguments[0].click();", more_button)
                print("   -> 'ìƒì„¸ ì •ë³´ ë” ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í–ˆìŠµë‹ˆë‹¤.")
                self._random_sleep()
            except Exception:
                print("   -> 'ìƒì„¸ ì •ë³´ ë” ë³´ê¸°' ë²„íŠ¼ì´ ì—†ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                pass


            soup = BeautifulSoup(self.driver.page_source, 'lxml')

            # 2. ì „ì²´ ë³¸ë¬¸ì„ ê°ì‹¸ëŠ” article íƒœê·¸ ì°¾ê¸°
            content_article = soup.select_one('article[class*="JobDescription_JobDescription"]')

            if content_article:
                description = content_article.text.strip()
            else:
                print("   -> [ê²½ê³ ] ê¸°ë³¸ ì„ íƒìë¡œ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 2ì°¨ ì„ íƒìë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")

                # h2 íƒœê·¸ ì¤‘ 'í¬ì§€ì…˜ ìƒì„¸'ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ ìš”ì†Œì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ”ë‹¤
                h2 = soup.find('h2', string='í¬ì§€ì…˜ ìƒì„¸')
                if h2 and h2.parent:
                    description = h2.parent.text.strip()
                
        except Exception as e:
            print(f" ğŸš¨ [ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜] {url} ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        
        return {'description': description, 'deadline':deadline}
 